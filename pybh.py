# -*- coding: utf-8 -*-
"""PyBH.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UUnyL-RYEH0zdGbIIN5SqAyzwm0njQWe

# EDA with Seaborn
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

df= pd.read_csv('/content/BostonHousing.csv')
df

df.head()

df.isnull().sum()

df.info()

df.columns

df.dtypes

df.tail()

df.describe()

df.shape

df.sample()

df.std()

df.loc[:,['crim','medv']]

df.chas.unique() #unique char

df.rad.unique() #unique char

df.mean

df.groupby('chas').size().plot(kind = 'pie', autopct = '%.0f%%', label = '');

sns.countplot(x = df['chas'], palette = 'flare');

df.groupby('rad').size().plot(kind = 'pie', autopct = '%.0f%%', label = '');

sns.countplot(x = df['rad'], palette = 'flare');

df.groupby('zn').size().plot(kind = 'pie', autopct = '%.0f%%', label = '');

sns.countplot(y = df['zn']).set(title = 'Property Value', 
                                       xlabel = 'count', 
                                       ylabel = 'zn');

# Solution zn without 0

dfzn=df.loc[df.zn > 0, :]
dfzn

sns.countplot(y = dfzn['zn']).set(title = 'Property Value', 
                                       xlabel = 'count', 
                                       ylabel = 'zn');

sns.countplot(y=df['rm']).set(title='Property Value', xlabel='count',ylabel='zn');

sns.barplot(data = df, x = 'rad', y = 'medv');

sns.barplot(data = df, x = 'chas', y = 'medv');

sns.barplot(data = df, x = 'rad', y = 'ptratio');

df_mean = df.groupby('rad').mean()
print(df_mean.head())
sns.barplot(data = df_mean, x = df_mean.index, y = 'medv');

sns.lineplot(data=df,x='crim',y='medv')

sns.lineplot(data=df,x='zn',y='medv')

sns.lineplot(data=df,x='age',y='medv')

sns.lineplot(data=df,x='dis',y='medv')

sns.lineplot(data=df,x='ptratio',y='medv')

sns.lineplot(data=df,x='medv',y='ptratio')

sns.lineplot(data=df,x='lstat',y='medv')

sns.histplot(x = df['medv']);

sns.histplot(x = df['rad']);

sns.histplot(x = df['lstat']);

sns.histplot(x = df['medv'], bins = 10);

sns.histplot(x = df['age'], bins = 10);

sns.histplot(data = df, x = 'medv', hue = 'chas', bins = 10);

sns.histplot(data = df, x = 'medv', hue = 'rad', bins = 15);

sns.boxplot(y = df['medv']);

sns.boxplot(x = df['age']);

sns.boxplot(x = df['lstat']);

sns.boxplot(data = df, x = 'rad', y = 'medv');

sns.violinplot(x = df['nox'], palette = 'rainbow');

sns.violinplot(data = df, x = 'chas', y = 'medv');

sns.countplot(data=df, x = 'crim');

sns.countplot(data=df, x = 'chas');

sns.countplot(data=df, x = 'lstat');

sns.pairplot(df)

sns.scatterplot(data = df, x = 'crim', y = 'medv');

sns.regplot(data = df, x = 'crim', y = 'medv');

sns.regplot(data = df, x = 'rm', y = 'medv');

sns.regplot(data = df, x = 'lstat', y = 'medv');

sns.scatterplot(data = df, x = 'crim', y = 'medv', size = 'ptratio');

"""# Exploratory Data Analysis(EDA) and Data Visualization"""

!pip install sweetviz

# importing sweetviz
import sweetviz as sv

#analyzing the dataset
bhreport = sv.analyze(df)

#display the report
bhreport.show_html('Boston Housing Dataset.html')

bhreport.show_notebook()

bhreport = sv.compare(df[100:], df[:100])
# bhreport.show_html('BostonH.html')

bhreport.show_notebook()

"""# Scikit-Learn (sklearn)"""

df.info()

df.shape

df.corr()['medv']   #y

df.corr()['crim']   #x

df.medv.head()

#split dataset in features and target variable
feature_cols = ['crim', 'zn', 'indus', 'chas', 'nox','rm','age','dis','rad','tax','ptratio','b','lstat']
X = df[feature_cols] # Features
y = df.medv # Target variable

y

import pandas as pd
data = pd.read_csv('/content/BostonHousing.csv', sep=';')


X1 = pd.DataFrame(df['crim'])
y1 = df['medv']


from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size = 0.25, random_state = 0)


from sklearn.linear_model import LinearRegression

model = LinearRegression()
model.fit(X_train, y_train) 
y1_pred = model.predict(X_test)

from sklearn.metrics import mean_squared_error, r2_score

print(f"RMSE: {(mean_squared_error(y_test, y1_pred))**0.5}")
print(f"R^2: {r2_score(y_test, y1_pred):.4f}")

import matplotlib.pyplot as plt

plt.scatter(X_test, y_test, color='black')
plt.plot(X_test, y1_pred, color='blue', linewidth=1)
plt.xlabel("crim")
plt.ylabel("medv")

plt.title('medv vs crim')
plt.show()

model.coef_

model.intercept_

X2 = pd.DataFrame(df['lstat'])
y2 = df['medv']

X_train,X_test,y_train,y_test=train_test_split(X2,y2,test_size=0.25,random_state=0)

model = LinearRegression(fit_intercept=True)

model.fit(X_train, y_train) 
y2_pred = model.predict(X_test)


from sklearn.metrics import mean_squared_error, r2_score

print(f"RMSE: {(mean_squared_error(y_test, y2_pred))**0.5}.")
print(f"R^2: {r2_score(y_test, y2_pred):.4f}")

import matplotlib.pyplot as plt

plt.scatter(X_test, y_test,  color='black')
plt.plot(X_test, y2_pred, color='blue', linewidth=1)
plt.xlabel("lstat")
plt.ylabel("medv")

plt.title('medv vs lstat')
plt.show()

model.coef_

model.intercept_

X3 = pd.DataFrame(df['rm'])
y3 = df['medv']

X_train,X_test,y_train,y_test=train_test_split(X3,y3,test_size=0.25,random_state=0)

model = LinearRegression(fit_intercept=True)

model.fit(X_train, y_train) 
y3_pred = model.predict(X_test)


from sklearn.metrics import mean_squared_error, r2_score

print(f"RMSE: {(mean_squared_error(y_test, y3_pred))**0.5}.")
print(f"R^2: {r2_score(y_test, y3_pred):.4f}")

import matplotlib.pyplot as plt

plt.scatter(X_test, y_test,  color='black')
plt.plot(X_test, y3_pred, color='blue', linewidth=1)
plt.xlabel("rm")
plt.ylabel("medv")

plt.title('medv vs rm')
plt.show()

model.coef_

model.intercept_

"""## Naive Bayes"""

type(df)

df

df2 = pd.DataFrame(df,columns=['chas',  'rad',  'tax'])

type(df2)

X_bh = df.drop(['medv','chas','tax','rad',], axis=1)  
y_bh = df['chas']

from sklearn.model_selection import train_test_split
X_train, X_test,y_train, y_test = train_test_split(X_bh, y_bh,random_state=0)
X_train.head()

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

from sklearn.naive_bayes import GaussianNB # 1. choose model class
model = GaussianNB()                       # 2. instantiate model
model.fit(X_train, y_train)                  # 3. fit model to data
y1_pred = model.predict(X_test)

# Accuracy

from sklearn.metrics import accuracy_score
accuracy_score(y_test, y1_pred)

# Precision

from sklearn.metrics import precision_score
precision_score(y_test, y1_pred)

# Recall

from sklearn.metrics import recall_score
recall_score(y_test, y1_pred)

from sklearn.metrics import classification_report

print(classification_report(y_test, y1_pred))
#F-measure = (2* Recall*Precision)/ (Recall + Precision)

# Confusion Matrix
from sklearn.metrics import confusion_matrix 
confusion_matrix(y_test, y1_pred)

#Confusion Matrix
import matplotlib.pyplot as plt
from sklearn import metrics
import numpy as np
confusion_matrix = metrics.confusion_matrix(y_test, y1_pred)

print(confusion_matrix)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix,display_labels=np.unique(y_bh))

cm_display.plot()
plt.show()

from sklearn.naive_bayes import GaussianNB # 1. choose model class
model = GaussianNB()                       # 2. instantiate model
model.fit(X_train, y_train)                  # 3. fit model to data
y2_pred = model.predict(X_test)

# Accuracy

from sklearn.metrics import accuracy_score
accuracy_score(y_test, y2_pred)

# Precision

from sklearn.metrics import precision_score
precision_score(y_test, y2_pred)

# Recall

from sklearn.metrics import recall_score
recall_score(y_test, y2_pred)

# Confusion Matrix
from sklearn.metrics import confusion_matrix 
confusion_matrix(y_test, y2_pred)

#Confusion Matrix
import matplotlib.pyplot as plt
from sklearn import metrics
import numpy as np
confusion_matrix = metrics.confusion_matrix(y_test, y2_pred)

print(confusion_matrix)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix,display_labels=np.unique(y_bh))

cm_display.plot()
plt.show()

from sklearn.metrics import classification_report

print(classification_report(y_test, y2_pred))
#F-measure = (2* Recall*Precision)/ (Recall + Precision)